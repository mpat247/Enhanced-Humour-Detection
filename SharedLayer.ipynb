{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "951b5e99-5400-4771-8dff-3651dec160ed",
   "metadata": {},
   "source": [
    "# Shared Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafd42e6-b97d-4eb0-ae96-b01a455ae974",
   "metadata": {},
   "source": [
    "## Manav Patel - 500967756\n",
    "## EE8228"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e7496-af7d-46ee-ae25-21fa65b1bdc6",
   "metadata": {},
   "source": [
    "### (a) Pretrain BERT on Short Jokes Datast for MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07c72def-978a-4d67-b355-eeef7f6e340e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded Training dataset from ./data/shortjokes/train.tsv\n",
      "Training dataset contains 173635 humorous and 173850 non-humorous jokes before filtering.\n",
      "Filtered out 173850 non-humorous jokes from Training dataset.\n",
      "Sampled 75,000 humorous jokes from Training dataset.\n",
      "Converted Training dataset to Hugging Face Dataset with 75000 samples.\n",
      "Successfully loaded Testing dataset from ./data/shortjokes/test.tsv\n",
      "Sampled 7,500 jokes from Testing dataset.\n",
      "Converted Testing dataset to Hugging Face Dataset with 7500 samples.\n",
      "\n",
      "First 5 rows of the training dataset:\n",
      "{'text': ['god it is time i punished the humans again jesus cool. flood or plague god[watching the apprentice] oh i have something way worse in mind..', 'sorry feminists... why do doctors slap babies butts when they come out to knock the balls off the dumb ones.', 'someone fucked up i got gary glitter in the mail.', 'the guyz l shadowrun returns l razor edge ep  l hes still there hi im karmit and i play video link well that is all i can really say. just want to advertise stuff link', 'fell asleep last night with the t.v. off. was that camping'], 'label': [1, 1, 1, 1, 1]}\n",
      "\n",
      "First 5 rows of the testing dataset:\n",
      "{'text': ['16971,outlawed in', '53136,when you date someone you either end up breaking up with them or marrying them... link either way you end up unhappy.', '46498,what is the most reliable thing about a honda it is theft rate.', '9584,clevelandâ€™s  wins are its most since its expansion rebirth.', '1566,dr paul robinson head of market intelligence at chks said there is no obvious clinical reason why growth in emergency admissions should differ between countries in the uk.']}\n"
     ]
    }
   ],
   "source": [
    "# Importing from the src directory\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "\n",
    "# Import the data loading and preprocessing function\n",
    "from data import load_and_preprocess, tokenize_and_mask\n",
    "\n",
    "# Define paths to datasets\n",
    "train_file_path = './data/shortjokes/train.tsv'\n",
    "test_file_path = './data/shortjokes/test.tsv'\n",
    "\n",
    "# Load and preprocess the datasets\n",
    "train_dataset_mlm = load_and_preprocess(train_file_path, \"Training dataset\")\n",
    "test_dataset_mlm = load_and_preprocess(test_file_path, \"Testing dataset\")\n",
    "\n",
    "# Display the first 5 rows of the datasets\n",
    "print(\"\\nFirst 5 rows of the training dataset:\")\n",
    "print(train_dataset_mlm[:5])\n",
    "\n",
    "print(\"\\nFirst 5 rows of the testing dataset:\")\n",
    "print(test_dataset_mlm[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f349629-b023-4e5a-8330-56a3b580d00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cdc9b865a9f4db6ac9b50778d7c6a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization and masking completed. Dataset now has features: {'text': Value(dtype='string', id=None), 'label': Value(dtype='int64', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87caa82438114212853bce2fef53ae0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization and masking completed. Dataset now has features: {'text': Value(dtype='string', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n",
      "\n",
      "Sample tokenized and masked data from training dataset:\n",
      "{'input_ids': tensor([  101,  2643,  2009,  2003,  2051,  1045, 14248,  1996,  4286,  2153,\n",
      "         4441,  4658,   103,  7186,  2030, 11629,  2643,   103,  3666,   103,\n",
      "        13357,  1033,  2821,  1045,   103,  2242,  2126,  4788,  1999,  2568,\n",
      "         1012,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        1012, -100, -100, -100, -100, 1031, -100, 1996, -100, -100, -100, -100,\n",
      "        2031, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100])}\n",
      "\n",
      "Sample tokenized and masked data from testing dataset:\n",
      "{'input_ids': tensor([  101, 28690,  2487,  1010, 29131,  1999,   102,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100])}\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and mask the training dataset\n",
    "train_tokenized = tokenize_and_mask(train_dataset_mlm)\n",
    "\n",
    "# Tokenize and mask the testing dataset\n",
    "test_tokenized = tokenize_and_mask(test_dataset_mlm)\n",
    "# Set the format of the datasets to PyTorch tensors\n",
    "train_tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "# View a sample from the tokenized training dataset\n",
    "print(\"\\nSample tokenized and masked data from training dataset:\")\n",
    "print(train_tokenized[0])\n",
    "\n",
    "# View a sample from the tokenized testing dataset\n",
    "print(\"\\nSample tokenized and masked data from testing dataset:\")\n",
    "print(test_tokenized[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "336ff665-84f4-4dd9-865e-3b67e00c57a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 09:48:50.299457: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForMaskedLM\n",
    "\n",
    "# Initialize the BERT model for Masked Language Modeling\n",
    "model_mlm = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bce8a7de-60c9-4004-8d51-7452bf8f68aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing model in ./models/bert-mlm. Loading the model...\n"
     ]
    }
   ],
   "source": [
    "from training import initialize_trainer, start_training, shared_evaluate_model\n",
    "# Initialize the Trainer\n",
    "trainer_mlm, model_mlm = initialize_trainer(\n",
    "    model=model_mlm,                      # Your initial BERT MLM model instance\n",
    "    train_dataset=train_tokenized,        # Tokenized training dataset\n",
    "    eval_dataset=test_tokenized,          # Tokenized evaluation dataset\n",
    "    output_dir='./models/bert-mlm',       # Output directory for models and checkpoints\n",
    "    logging_dir='./output/logs',          # Logging directory\n",
    "    learning_rate=5e-5,                   # Learning rate\n",
    "    num_train_epochs=4,                   # Number of training epochs\n",
    "    per_device_train_batch_size=16,       # Training batch size\n",
    "    per_device_eval_batch_size=32,        # Evaluation batch size\n",
    "    logging_steps=500,                    # Log metrics every 500 steps\n",
    "    save_steps=10_000,                    # Save checkpoint every 10,000 steps\n",
    "    eval_steps=10_000,                    # Evaluate every 10,000 steps\n",
    "    save_total_limit=2                     # Keep only the 2 most recent checkpoints\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "400d8299-773b-4686-9a9d-5651b6bd3987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training skipped. Pretrained model loaded.\n",
      "Training skipped. Pretrained model loaded.\n"
     ]
    }
   ],
   "source": [
    "# Start the training process\n",
    "train_result_mlm, trained_model_mlm = start_training(trainer_mlm)\n",
    "\n",
    "if train_result_mlm is None:\n",
    "    print(\"Training skipped. Pretrained model loaded.\")\n",
    "else:\n",
    "    print(\"Training completed and model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96132f1b-0d95-4f7c-bc69-3da096c2d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from training import shared_initialize_classification_trainer, shared_start_training\n",
    "from data import shared_load_and_preprocess_classification_data, shared_tokenize_classification_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b33d33c-aec8-421b-8177-ecd53ddbd9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution before sampling:\n",
      "label\n",
      "0    210925\n",
      "1    210730\n",
      "Name: count, dtype: int64\n",
      "Balanced dataset created with 150000 samples.\n",
      "Label distribution after balancing:\n",
      "label\n",
      "0    75000\n",
      "1    75000\n",
      "Name: count, dtype: int64\n",
      "Loaded and preprocessed classification data. Number of samples: 150000\n",
      "Train dataset size: 120000\n",
      "Eval dataset size: 30000\n"
     ]
    }
   ],
   "source": [
    "# Path to the classification dataset\n",
    "shared_data_path = './data/preprocessed_combined_dataset.csv'\n",
    "\n",
    "# Load and preprocess the classification dataset\n",
    "shared_dataset, shared_label_encoder = shared_load_and_preprocess_classification_data(shared_data_path)\n",
    "\n",
    "# Split the dataset into training and evaluation sets\n",
    "shared_dataset = shared_dataset.train_test_split(test_size=0.2)\n",
    "shared_train = shared_dataset['train']\n",
    "shared_test = shared_dataset['test']\n",
    "\n",
    "print(f\"Train dataset size: {len(shared_train)}\")\n",
    "print(f\"Eval dataset size: {len(shared_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0bea09e-9a9b-4ffb-930f-3ac327dcc69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0455a245354158a479a86c1ea575c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization for classification completed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c41ca1e49f4c2597ee0a2c770d9b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization for classification completed.\n",
      "Tokenized train dataset size: 120000\n",
      "Tokenized eval dataset size: 30000\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the training and evaluation datasets\n",
    "train_tokenized_shared = shared_tokenize_classification_data(shared_train)\n",
    "eval_tokenized_shared = shared_tokenize_classification_data(shared_test)\n",
    "\n",
    "print(f\"Tokenized train dataset size: {len(train_tokenized_shared)}\")\n",
    "print(f\"Tokenized eval dataset size: {len(eval_tokenized_shared)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63e491a3-5909-4f26-a5e7-55ad39d48820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing classification model in ./models/bert-classification. Loading the model...\n"
     ]
    }
   ],
   "source": [
    "# Initialize the classification trainer\n",
    "shared_trainer_classification, shared_classification_model = shared_initialize_classification_trainer(\n",
    "    model_dir='./models/bert-mlm',                   # Directory of the pretrained MLM model\n",
    "    train_dataset=train_tokenized_shared,            # Tokenized training dataset\n",
    "    eval_dataset=eval_tokenized_shared,              # Tokenized evaluation dataset\n",
    "    output_dir='./models/bert-classification',       # Output directory for classification model\n",
    "    logging_dir='./output/logs_classification',      # Logging directory\n",
    "    learning_rate=5e-5,                              # Learning rate\n",
    "    num_train_epochs=4,                              # Number of training epochs\n",
    "    per_device_train_batch_size=16,                  # Training batch size\n",
    "    per_device_eval_batch_size=32,                   # Evaluation batch size\n",
    "    logging_steps=500,                               # Log metrics every 500 steps\n",
    "    save_steps=10_000,                               # Save checkpoint every 10,000 steps\n",
    "    eval_steps=10_000,                               # Evaluate every 10,000 steps\n",
    "    save_total_limit=2,                              # Keep only the 2 most recent checkpoints\n",
    "    gradient_accumulation_steps=4                    # Simulate larger batch size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81679da9-f13c-420b-92fe-3bd1ca3d7c5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training skipped. Pretrained classification model loaded.\n",
      "Training was skipped. Pretrained classification model loaded.\n"
     ]
    }
   ],
   "source": [
    "# Start the classification training process\n",
    "shared_train_result, shared_trained_model = shared_start_training(shared_trainer_classification)\n",
    "\n",
    "if shared_train_result is None:\n",
    "    print(\"Training was skipped. Pretrained classification model loaded.\")\n",
    "else:\n",
    "    print(\"Classification training completed and model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a57ae54-67a8-4df7-a655-fdf2478bc814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics successfully saved to ./output/reports/evaluation_metrics.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Convert NumPy arrays and other non-serializable objects in the metrics dictionary to serializable types\n",
    "def make_json_serializable(data):\n",
    "    \"\"\"\n",
    "    Recursively converts non-serializable objects (e.g., NumPy arrays) in a dictionary to serializable types.\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        return {key: make_json_serializable(value) for key, value in data.items()}\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        return data.tolist()  # Convert NumPy arrays to lists\n",
    "    elif isinstance(data, (np.float32, np.float64)):  # Convert NumPy floats to Python floats\n",
    "        return float(data)\n",
    "    elif isinstance(data, (np.int32, np.int64)):  # Convert NumPy integers to Python integers\n",
    "        return int(data)\n",
    "    return data  # Leave other types unchanged\n",
    "\n",
    "\n",
    "# Example: Saving the metrics to ./output/reports\n",
    "output_dir = \"./output/reports\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "# Convert the metrics to a JSON-serializable format\n",
    "serializable_metrics = make_json_serializable(metrics)\n",
    "\n",
    "# Filepath to save the metrics\n",
    "output_file = os.path.join(output_dir, \"evaluation_metrics.json\")\n",
    "\n",
    "# Save the metrics to a JSON file\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(serializable_metrics, f, indent=4)\n",
    "\n",
    "print(f\"Metrics successfully saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcf02d41-dd60-4363-abe7-bc709d5eb6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution before sampling:\n",
      "label\n",
      "1    15000\n",
      "0    15000\n",
      "Name: count, dtype: int64\n",
      "Balanced dataset created with 30000 samples.\n",
      "Label distribution after balancing:\n",
      "label\n",
      "0    15000\n",
      "1    15000\n",
      "Name: count, dtype: int64\n",
      "Loaded and preprocessed classification data. Number of samples: 30000\n",
      "{'text': ['Shakespeare wrote many famous plays, including Hamlet and Romeo and Juliet.', 'Iâ€™m reading a book about anti-gravity. Itâ€™s impossible to put down.', 'I donâ€™t trust people who do acupunctureâ€”theyâ€™re back stabbers.', \"I don't trust stairs. They're always up to something.\", 'An apple a day keeps the doctor away.', 'The speed of sound is faster in water than in air.', 'The speed of light is approximately 299,792 kilometers per second.', 'The capital of France is Paris.', 'Water boils at 100 degrees Celsius at sea level.', 'What do you call a pile of cats? A meow-tain.'], 'labels': [0, 1, 1, 1, 0, 0, 0, 0, 0, 1]}\n",
      "Train dataset size: 0\n",
      "Eval dataset size: 30000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5cb3ae3b6fe43e7813243d25ed38532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization for classification completed.\n",
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n",
      "Evaluating on a subset of 27000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [02:20<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.8153\n",
      "Precision: 0.8651\n",
      "Recall: 0.8153\n",
      "F1 Score: 0.8088\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 8519  4987]\n",
      " [    0 13494]]\n",
      "Overall Accuracy: 0.8152962962962963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from transformers import BertForSequenceClassification\n",
    "from training import shared_evaluate_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset\n",
    "\n",
    "sys.path.append('./output')\n",
    "\n",
    "shared_data_path2 = './data/humor_nonhumor_dataset_v7.csv'\n",
    "\n",
    "# Load the CSV file\n",
    "df2 = pd.read_csv(shared_data_path2)\n",
    "\n",
    "# Clean the 'text' column\n",
    "df2['text'] = df2['text'].astype(str).str.strip()\n",
    "\n",
    "# Check if there are enough samples for both labels\n",
    "label_counts2 = df2['label'].value_counts()\n",
    "print(f\"Label distribution before sampling:\\n{label_counts2}\")\n",
    "\n",
    "# Sample 15,000 rows for each label\n",
    "balanced_df2 = pd.concat([\n",
    "    df2[df2['label'] == 0].sample(n=15000, random_state=42),\n",
    "    df2[df2['label'] == 1].sample(n=15000, random_state=42)\n",
    "])\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "balanced_df2 = balanced_df2.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Balanced dataset created with {len(balanced_df2)} samples.\")\n",
    "print(f\"Label distribution after balancing:\\n{balanced_df2['label'].value_counts()}\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder2 = LabelEncoder()\n",
    "balanced_df2['labels'] = label_encoder2.fit_transform(balanced_df2['label'])\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "dataset2 = Dataset.from_pandas(balanced_df2[['text', 'labels']])\n",
    "\n",
    "print(f\"Loaded and preprocessed classification data. Number of samples: {len(dataset2)}\")\n",
    "\n",
    "print(dataset2[:10])\n",
    "\n",
    "# Treat the entire dataset as the test set (no split)\n",
    "shared_train2 = dataset2.select([])  # Empty training set\n",
    "shared_test2 = dataset2  # Entire dataset as test set\n",
    "\n",
    "print(f\"Train dataset size: {len(shared_train2)}\")  # Will be 0\n",
    "print(f\"Eval dataset size: {len(shared_test2)}\")  # Will be the entire dataset\n",
    "\n",
    "# Tokenizing the evaluation dataset using the existing tokenization function\n",
    "eval_tokenized_shared2 = shared_tokenize_classification_data(shared_test2)\n",
    "\n",
    "# Load the pre-trained BERT model\n",
    "shared_classification_model2 = BertForSequenceClassification.from_pretrained('./models/bert-classification')\n",
    "\n",
    "print(shared_classification_model2)\n",
    "\n",
    "# Evaluate the model\n",
    "metrics2 = shared_evaluate_model(shared_classification_model2, eval_tokenized_shared2, batch_size=32, sample_fraction=0.9)\n",
    "print(\"Overall Accuracy:\", metrics2['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bce5cb73-b387-4e14-ab0d-d52c45d3a834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Why don't skeletons fight each other? They don't have the guts.' is humorous.\n",
      "'I told my computer I needed a break, and now it won't stop sending me ads for vacations.' is humorous.\n",
      "'Why donâ€™t scientists trust atoms? Because they make up everything!' is humorous.\n",
      "'I asked the librarian if the library had any books on paranoia. She whispered, 'They're right behind you.'' is humorous.\n",
      "'Parallel lines have so much in common. Itâ€™s a shame theyâ€™ll never meet.' is humorous.\n",
      "'The sun sets in the west every evening.' is not humorous.\n",
      "'Mountains are beautiful, but they have no ears.' is humorous.\n",
      "'The wind howls in the middle of the night.' is not humorous.\n",
      "'She smiled as the clock struck midnight.' is humorous.\n",
      "'There is a tree in my backyard that grows very tall.' is humorous.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_path = './models/bert-classification'  # Update with your path to the model\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define 5 jokes and 5 regular sentences\n",
    "sentences = [\n",
    "    \"Why don't skeletons fight each other? They don't have the guts.\",  # Joke 1\n",
    "    \"I told my computer I needed a break, and now it won't stop sending me ads for vacations.\",  # Joke 2\n",
    "    \"Why donâ€™t scientists trust atoms? Because they make up everything!\",  # Joke 3\n",
    "    \"I asked the librarian if the library had any books on paranoia. She whispered, 'They're right behind you.'\",  # Joke 4\n",
    "    \"Parallel lines have so much in common. Itâ€™s a shame theyâ€™ll never meet.\",  # Joke 5\n",
    "    \"The sun sets in the west every evening.\",  # Regular sentence 1\n",
    "    \"Mountains are beautiful, but they have no ears.\",  # Regular sentence 2\n",
    "    \"The wind howls in the middle of the night.\",  # Regular sentence 3\n",
    "    \"She smiled as the clock struck midnight.\",  # Regular sentence 4\n",
    "    \"There is a tree in my backyard that grows very tall.\",  # Regular sentence 5\n",
    "]\n",
    "\n",
    "# Loop through the sentences\n",
    "for sentence in sentences:\n",
    "    # Tokenize the sentence\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Get prediction (0 or 1)\n",
    "    prediction = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Print result\n",
    "    if prediction == 0:\n",
    "        print(f\"'{sentence}' is not humorous.\")\n",
    "    else:\n",
    "        print(f\"'{sentence}' is humorous.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3feba9-2850-4631-b921-1f5b8341a4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
